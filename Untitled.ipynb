{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41db8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f681f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15493148340429122912\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 2245525504\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 320572782922892479\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78af5eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SATYANKAR\\AppData\\Local\\Temp\\ipykernel_18736\\337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be85f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9ed96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdbd9cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b639fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d14820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232c35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64470757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ee3448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784c6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "for devices in visible_devices:\n",
    "  print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b668da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_gpu_selection(usage_max=0.01, mem_max=0.05):\n",
    "\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "    log = str(subprocess.check_output(\"nvidia-smi\", shell=True)).split(r\"\\n\")[6:-1]\n",
    "    gpu = 0\n",
    "\n",
    "    # Maximum of GPUS, 8 is enough for most\n",
    "    for i in range(8):\n",
    "        idx = i*3 + 2\n",
    "        if idx > log.__len__()-1:\n",
    "            break\n",
    "        inf = log[idx].split(\"|\")\n",
    "        if inf.__len__() < 3:\n",
    "            break\n",
    "        usage = int(inf[3].split(\"%\")[0].strip())\n",
    "        mem_now = int(str(inf[2].split(\"/\")[0]).strip()[:-3])\n",
    "        mem_all = int(str(inf[2].split(\"/\")[1]).strip()[:-3])\n",
    "        # print(\"GPU-%d : Usage:[%d%%]\" % (gpu, usage))\n",
    "        if usage < 100*usage_max and mem_now < mem_max*mem_all:\n",
    "            os.environ[\"CUDA_VISIBLE_EVICES\"] = str(gpu)\n",
    "            print(\"\\nAuto choosing vacant GPU-%d : Memory:[%dMiB/%dMiB] , GPU-Util:[%d%%]\\n\" %\n",
    "                  (gpu, mem_now, mem_all, usage))\n",
    "            return\n",
    "        print(\"GPU-%d is busy: Memory:[%dMiB/%dMiB] , GPU-Util:[%d%%]\" %\n",
    "              (gpu, mem_now, mem_all, usage))\n",
    "        gpu += 1\n",
    "    print(\"\\nNo vacant GPU, use CPU instead\\n\")\n",
    "    os.environ[\"CUDA_VISIBLE_EVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d9c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d69eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_available_gpus():\n",
    "        physical_gpus = tf.config.list_physical_devices(device_type=\"GPU\")\n",
    "        return [(x, tf.config.experimental.get_device_details(x)) for x in physical_gpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5cdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7045a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
